// server.js â€“ UPLashes AI backend (wersja docelowa)

const express = require("express");
const cors = require("cors");
const multer = require("multer");
const OpenAI = require("openai");

const app = express();
const PORT = process.env.PORT || 10000;

// Middleware
app.use(cors());
app.use(express.json());

// Multer â€“ plik w pamiÄ™ci, max 8 MB
const upload = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: 8 * 1024 * 1024 }, // 8 MB
});

// Klient OpenAI â€“ na Render MUSI byÄ‡ ustawiona zmienna OPENAI_API_KEY
const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ðŸ”¹ Prosty healthcheck â€“ Å¼ebyÅ› mogÅ‚a sprawdziÄ‡, czy backend Å¼yje
app.get("/", (req, res) => {
  res.send("UPLashes AI backend dziaÅ‚a âœ…");
});

app.get("/ping", (req, res) => {
  res.json({
    ok: true,
    message: "UPLashes AI backend dziaÅ‚a i odpowiada na /ping",
  });
});

// ðŸ”¹ GÅ‚Ã³wna trasa analizy
app.post("/analyze", upload.single("image"), async (req, res) => {
  try {
    // 1) Czy na pewno przyszÅ‚o zdjÄ™cie?
    if (!req.file) {
      return res.status(400).json({
        ok: false,
        error: "Brak pliku obrazu. PrzeÅ›lij zdjÄ™cie oka z rzÄ™sami.",
      });
    }

    // 2) Zamiana na data URL dla modelu
    const base64 = req.file.buffer.toString("base64");
    const imageDataUrl = `data:${req.file.mimetype};base64,${base64}`;

    // 3) Prompt â€“ logika A / B / C
    const prompt = `JesteÅ› ekspertem od stylizacji rzÄ™s i piszesz raporty dla aplikacji UPLashes AI.

Twoje zadanie:

1. Najpierw w myÅ›lach zaklasyfikuj obraz do jednej z trzech kategorii:
   - A) "extensions" â€“ widzÄ™ oko z zaaplikowanymi rzÄ™sami (przedÅ‚uÅ¼anie, kÄ™pki, volume).
   - B) "natural" â€“ widzÄ™ oko, ale rzÄ™sy wyglÄ…dajÄ… na naturalne, bez stylizacji.
   - C) "invalid" â€“ nie widzÄ™ wyraÅºnego zbliÅ¼enia jednego oka z rzÄ™sami (np. zdjÄ™cie z daleka, inny obiekt, zbyt ciemne / rozmazane).

2. Na podstawie tej klasyfikacji ZWRÃ“Ä† TYLKO gotowy raport w **markdown po polsku**, BEZ JSON, BEZ wypisywania liter A/B/C.

=== DLA A) extensions ===
Napisz raport pod nagÅ‚Ã³wkiem:

### AI.UPLashes Report

NastÄ™pnie w punktach:

1. **GÄ™stoÅ›Ä‡ i pokrycie** â€“ oceÅ„ gÄ™stoÅ›Ä‡ aplikacji, czy widaÄ‡ luki, dziury, zbyt puste lub zbyt ciÄ™Å¼kie miejsca.
2. **Kierunek i gÃ³rna linia** â€“ czy rzÄ™sy ukÅ‚adajÄ… siÄ™ w podobnym kierunku, czy gÃ³rna linia jest rÃ³wna i estetyczna, czy coÅ› â€žwyskakujeâ€ z linii.
3. **Mapowanie i styl** â€“ do jakiego efektu jest najbliÅ¼ej (np. 1:1, 2â€“3D, 4â€“6D, mega volume, doll eye, fox eye, kim, wet look itd.), jak rozÅ‚oÅ¼one sÄ… dÅ‚ugoÅ›ci.
4. **JakoÅ›Ä‡ przyklejenia** â€“ czy widaÄ‡ sklejki, odstajÄ…ce rzÄ™sy, krzyÅ¼ujÄ…ce siÄ™ podstawy, czy linia przyklejenia jest czysta.
5. **BezpieczeÅ„stwo i komfort** â€“ czy widaÄ‡ zaczerwienienie, podraÅ¼nienia, zbyt ciÄ™Å¼kie kÄ™pki, niebezpieczne odklejenia.

Na koÅ„cu dodaj sekcjÄ™:

### WskazÃ³wki do poprawy

i wypisz konkretne, praktyczne tipy dla stylistki (co moÅ¼e zrobiÄ‡ lepiej przy kolejnej aplikacji).

=== DLA B) natural ===
TakÅ¼e uÅ¼yj nagÅ‚Ã³wka:

### AI.UPLashes Report

WyjaÅ›nij jasno, Å¼e na zdjÄ™ciu NIE WIDZISZ stylizacji rzÄ™s â€“ tylko naturalne rzÄ™sy, dlatego nie moÅ¼esz oceniÄ‡ wykonanej aplikacji.
NastÄ™pnie zaproponuj 2â€“3 warianty stylizacji, ktÃ³re mogÅ‚yby pasowaÄ‡ do tego oka, np.:

- delikatne 1:1 dla bardzo naturalnego efektu,
- 2â€“3D dla subtelnej objÄ™toÅ›ci,
- 4â€“6D lub mega volume dla mocnego efektu, jeÅ›li klientka lubi dramatyczny look.

Daj krÃ³tkie uzasadnienie, do kogo / jakiego typu klientki kaÅ¼da propozycja pasuje.

=== DLA C) invalid ===
UÅ¼yj nagÅ‚Ã³wka:

### AI.UPLashes Report

i napisz krÃ³tki komunikat w stylu:
"Nie widzÄ™ na zdjÄ™ciu wyraÅºnego oka z rzÄ™sami do analizy. ProszÄ™ wgraÄ‡ zdjÄ™cie jednego oka z bliska, ostre, dobrze doÅ›wietlone, bez filtra."

BARDZO WAÅ»NE:
- Nigdy nie udawaj, Å¼e widzisz stylizacjÄ™, jeÅ›li jej nie ma.
- JeÅ›li nie masz pewnoÅ›ci, zachowuj siÄ™ jak kategoria C.
- Nie wypisuj kategorii A/B/C â€“ tylko gotowy raport w markdown.
- Pisz wyÅ‚Ä…cznie po polsku.`;

    // 4) WywoÅ‚anie modelu z obrazem
    const response = await client.responses.create({
      model: "gpt-4.1-mini",
      input: [
        {
          role: "user",
          content: [
            { type: "input_text", text: prompt },
            { type: "input_image", image_url: imageDataUrl },
          ],
        },
      ],
    });

    const text =
      response.output?.[0]?.content?.[0]?.text?.trim() ||
      "Nie udaÅ‚o siÄ™ wygenerowaÄ‡ raportu dla tego zdjÄ™cia.";

    // 5) Sukces â€“ frontend oczekuje statusu 200
    return res.json({
      ok: true,
      reportMarkdown: text,
    });
  } catch (error) {
    console.error("BÅ‚Ä…d w /analyze:", error);

    return res.status(500).json({
      ok: false,
      error: "BÅ‚Ä…d po stronie serwera podczas analizy obrazu.",
    });
  }
});

// Start serwera
app.listen(PORT, () => {
  console.log(`UPLashes AI backend listening on port ${PORT}`);
});
